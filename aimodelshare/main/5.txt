#Tabular Regression Prediction Runtime Code

import boto3
import pandas as pd
import os
import numpy as np
import onnxruntime as rt
import json
import sklearn

def get_model_onnx(runtimemodel_s3_filename="runtime_model.onnx"):
  s3 = boto3.resource("s3")
  bucket = s3.Bucket("{0}")

  with open("/tmp/runtime_model.onnx", "wb") as modelfo:
      bucket.download_fileobj("{1}/runtime_model.onnx",  modelfo)
  model = rt.InferenceSession("/tmp/runtime_model.onnx")
  return model

def get_preprocessor(preprocessor_s3_filename="runtime_preprocessor.zip"):
    import pickle
    from zipfile import ZipFile
    from io import BytesIO
    import os
    import sklearn
    s3 = boto3.resource("s3")
    bucket = s3.Bucket("{0}")
    
    zip_obj = s3.Object(bucket_name="{0}", key="{1}/runtime_preprocessor.zip")
    buffer = BytesIO(zip_obj.get()["Body"].read())
    z = ZipFile(buffer)
    # Extract all the contents of zip file in current directory
    z.extractall("/tmp/")
    
    folderpath=os.path.dirname(os.path.abspath("/tmp/preprocessor.py"))
    file_name=os.path.basename("/tmp/preprocessor.py")

    #Then import all pkl files you want from bucket (need to generate this list from...
    # function globals)
    import os
    pickle_file_list=[]
    for file in os.listdir(folderpath):
          if file.endswith(".pkl"):
              pickle_file_list.append(os.path.join(folderpath, file))

    for i in pickle_file_list: 
          objectname=str(os.path.basename(i)).replace(".pkl","")
          objects={objectname:""}
          globals()[objectname]=pickle.load(open(str(i), "rb" ) )
      # First import preprocessor function to session from preprocessor.py
    exec(open(os.path.join(folderpath,'preprocessor.py')).read(),globals())
    return preprocessor

def get_runtimedata(runtimedata_s3_filename="runtime_data.json"):

      s3 = boto3.resource('s3')
      obj = s3.Object("{0}", "{1}"+"/"+runtimedata_s3_filename)
      runtime_data = json.load(obj.get()['Body'])

      return runtime_data


runtime_data=get_runtimedata(runtimedata_s3_filename="runtime_data.json")

preprocessor_type=runtime_data["runtime_preprocessor"]

runtime_model=runtime_data["runtime_model"]["name"]

# Load model
model=get_model_onnx(runtimemodel_s3_filename='runtime_model.onnx')

# Load preprocessor
preprocessor=get_preprocessor(preprocessor_s3_filename="runtime_preprocessor.zip")


def predict(event,model,preprocessor):
    body = event["body"]
    import six
    if isinstance(event["body"], six.string_types):
        body = json.loads(event["body"])
        print(body["data"])
        bodydata = pd.DataFrame.from_dict(body["data"])
    else:
        print(body["data"])
        bodydata = pd.DataFrame.from_dict(body["data"])
        print(bodydata)

    input_name = model.get_inputs()[0].name
    print(input_name)

	#Preprocess data
    input_data = preprocessor(bodydata).astype('float32') #needs to be float32
    print(input_data)
	
    # Generate prediction using preprocessed input data

    res=model.run(None,  {input_name: input_data})
    
    result = res[0].tolist()[0]

    return result

def handler(event, context):
        result = predict(event,model,preprocessor)
        return {"statusCode": 200,
        "headers": {
        "Access-Control-Allow-Origin" : "*",
        "Access-Control-Allow-Credentials": True,
        "Allow" : "GET, OPTIONS, POST",
        "Access-Control-Allow-Methods" : "GET, OPTIONS, POST",
        "Access-Control-Allow-Headers" : "*"
        },
        "body": json.dumps(result)}