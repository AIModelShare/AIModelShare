import boto3
import pickle
from zipfile import ZipFile
from io import BytesIO
import os
import onnxruntime as rt
import json

s3 = boto3.resource("s3")


def load_onnx_model(filename="runtime_model.onnx"):
    bucket = s3.Bucket("$bucket_name")

    with open("/tmp/"+filename, "wb") as f:
        bucket.download_fileobj("$unique_model_id/"+filename,  f)
    model = rt.InferenceSession("/tmp/"+filename)

    return model

def get_runtimedata(runtimedata_s3_filename="runtime_data.json"):
    s3 = boto3.resource('s3')
    obj = s3.Object("$bucket_name", "$unique_model_id" +
                    "/"+runtimedata_s3_filename)
    runtime_data = json.load(obj.get()['Body'])

    return runtime_data


def get_preprocessor(preprocessor_s3_filename="runtime_preprocessor.zip"):
    
    bucket = s3.Bucket("$bucket_name")

    zip_obj = s3.Object(bucket_name="$bucket_name",
                        key="$unique_model_id/runtime_preprocessor.zip")
    buffer = BytesIO(zip_obj.get()["Body"].read())
    z = ZipFile(buffer)
    # Extract all the contents of zip file in current directory
    z.extractall("/tmp/")

    folderpath = os.path.dirname(os.path.abspath("/tmp/preprocessor.py"))
    file_name = os.path.basename("/tmp/preprocessor.py")

    #Then import all pkl files you want from bucket (need to generate this list from...
    # function globals)
    import os
    pickle_file_list = []
    for file in os.listdir(folderpath):
        if file.endswith(".pkl"):
            pickle_file_list.append(os.path.join(folderpath, file))

    for i in pickle_file_list:
        objectname = str(os.path.basename(i)).replace(".pkl", "")
        objects = {objectname: ""}
        globals()[objectname] = pickle.load(open(str(i), "rb"))
      # First import preprocessor function to session from preprocessor.py
    exec(open(os.path.join(folderpath, 'preprocessor.py')).read(), globals())
    return preprocessor