,keras,hex,aims_category,keras_category,torch_category,docs,description
0,AbstractRNNCell,#f1e2cc,Sequential,Recurrent Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/AbstractRNNCell,This is the base class for implementing RNN cells with custom behavior.
1,Activation,,Activation,Core Layers,,https://keras.io/api/layers/core_layers/activation/,Applies an activation function to an output.
2,ActivityRegularization,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/activity_regularization/,Layer that applies an update to the cost function based input activity.
3,Add,,Tensor operation,Merging Layer,,https://keras.io/api/layers/merging_layers/add/,"Layer that adds a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape)."
4,AdditiveAttention,#f4cae4,Transformer,Attention Layers,,https://keras.io/api/layers/attention_layers/additive_attention/,"Additive attention layer, a.k.a. Bahdanau-style attention."
5,AlphaDropout,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/alpha_dropout/,"Applies Alpha Dropout to the input. Alpha Dropout is a Dropout that keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout. Alpha Dropout fits well to Scaled Exponential Linear Units by randomly setting activations to the negative saturation value."
6,Attention,#f4cae4,Transformer,Attention Layers,,https://keras.io/api/layers/attention_layers/attention/,"Dot-product attention layer, a.k.a. Luong-style attention."
7,Average,,Tensor operation,Merging Layer,,https://keras.io/api/layers/merging_layers/average/,"Layer that averages a list of inputs element-wise. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape)."
8,AveragePooling1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/average_pooling1d/,"Average pooling for temporal data. Downsamples the input representation by taking the average value over the window defined by pool_size. The window is shifted by strides. The resulting output when using ""valid"" padding option has a shape of: output_shape = (input_shape - pool_size + 1) / strides). The resulting output shape when using the ""same"" padding option is: output_shape = input_shape / strides."
9,AveragePooling2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/average_pooling2d/,"Average pooling operation for spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension. The resulting output when using ""valid"" padding option has a shape (number of rows or columns) of: output_shape = math.floor((input_shape - pool_size) / strides) + 1 (when input_shape >= pool_size). The resulting output shape when using the ""same"" padding option is: output_shape = math.floor((input_shape - 1) / strides) + 1."
10,AveragePooling3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/average_pooling3d/,"Average pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension."
11,AvgPool1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/average_pooling1d/,"Average pooling for temporal data. Downsamples the input representation by taking the average value over the window defined by pool_size. The window is shifted by strides. The resulting output when using ""valid"" padding option has a shape of: output_shape = (input_shape - pool_size + 1) / strides). The resulting output shape when using the ""same"" padding option is: output_shape = input_shape / strides."
12,AvgPool2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/average_pooling2d/,"Average pooling operation for spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension. The resulting output when using ""valid"" padding option has a shape (number of rows or columns) of: output_shape = math.floor((input_shape - pool_size) / strides) + 1 (when input_shape >= pool_size). The resulting output shape when using the ""same"" padding option is: output_shape = math.floor((input_shape - 1) / strides) + 1."
13,AvgPool3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/average_pooling3d/,"Average pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension."
14,BatchNormalization,#cbd5e8,Regularization,Normalization Layers,,https://keras.io/api/layers/normalization_layers/batch_normalization/,"Layer that normalizes its inputs. Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1. Importantly, batch normalization works differently during training and during inference."
15,Bidirectional,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/bidirectional/,Bidirectional wrapper for RNNs.
16,CategoryEncoding,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding/,"A preprocessing layer which encodes integer features. This layer provides options for condensing data into a categorical encoding when the total number of tokens are known in advance. It accepts integer values as inputs, and it outputs a dense or sparse representation of those inputs. For integer inputs where the total number of tokens is not known, use tf.keras.layers.IntegerLookup instead."
17,CenterCrop,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/center_crop/,"A preprocessing layer which crops images. This layers crops the central portion of the images to a target size. If an image is smaller than the target size, it will be resized and cropped so as to return the largest possible window in the image that matches the target aspect ratio."
18,Concatenate,,Tensor operation,Merging Layers,,https://keras.io/api/layers/merging_layers/concatenate/,"Layer that concatenates a list of inputs. It takes as input a list of tensors, all of the same shape except for the concatenation axis, and returns a single tensor that is the concatenation of all inputs."
19,Conv1D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/convolution1d/,"1D convolution layer (e.g. temporal convolution). This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well."
20,Conv1DTranspose,#fdcdac,Convolution,Convolution Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose,"Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution."
21,Conv2D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/convolution2d/,"2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well."
22,Conv2DTranspose,#fdcdac,Convolution,Convolution Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose,"Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution."
23,Conv3D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/convolution3d/,"3D convolution layer (e.g. spatial convolution over volumes). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well."
24,Conv3DTranspose,#fdcdac,Convolution,Convolution Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3DTranspose,"Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution."
25,ConvLSTM1D,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/conv_lstm1d/,"1D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional."
26,ConvLSTM2D,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/conv_lstm2d/,"2D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional."
27,ConvLSTM3D,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/conv_lstm3d/,"3D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional."
28,Convolution1D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/convolution1d/,"1D convolution layer (e.g. temporal convolution). This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well."
29,Convolution1DTranspose,#fdcdac,Convolution,Convolution Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose,"Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution."
30,Convolution2D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/convolution2d/,"2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well."
31,Convolution2DTranspose,#fdcdac,Convolution,Convolution Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose,"Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution."
32,Convolution3D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/convolution3d/,"3D convolution layer (e.g. spatial convolution over volumes). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well."
33,Convolution3DTranspose,#fdcdac,Convolution,Convolution Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3DTranspose,"Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution."
34,Cropping1D,,Tensor operation,Reshaping Layers,,https://keras.io/api/layers/reshaping_layers/cropping1d/,Cropping layer for 1D input (e.g. temporal sequence). It crops along the time dimension (axis 1).
35,Cropping2D,,Tensor operation,Reshaping Layers,,https://keras.io/api/layers/reshaping_layers/cropping2d/,"Cropping layer for 2D input (e.g. picture).

It crops along spatial dimensions, i.e. height and width."
36,Cropping3D,,Tensor operation,Reshaping Layers,,https://keras.io/api/layers/reshaping_layers/cropping3d/,Cropping layer for 3D data (e.g. spatial or spatio-temporal).
37,Dense,#fff2ae,Dense,Core Layers,,https://keras.io/api/layers/core_layers/dense/,"Just your regular densely-connected NN layer. Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True). These are all attributes of Dense."
38,DenseFeatures,,,,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/DenseFeatures,A layer that produces a dense Tensor based on given feature_columns.
39,DepthwiseConv2D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/depthwise_convolution2d/,Depthwise convolution is a type of convolution in which each input channel is convolved with a different kernel (called a depthwise kernel). You can understand depthwise convolution as the first step in a depthwise separable convolution.
40,Discretization,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/numerical/discretization/,A preprocessing layer which buckets continuous features by ranges. This layer will place each element of its input data into one of several contiguous ranges and output an integer index indicating which range each element was placed in.
41,Dot,,Tensor operation,Merging Layer,,https://keras.io/api/layers/merging_layers/dot/,Layer that computes a dot product between samples in two tensors.
42,Dropout,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/dropout/,"Applies Dropout to the input. The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged."
43,Embedding,#b3e2cd,Embedding,Core Layers,,https://keras.io/api/layers/core_layers/embedding/,Turns positive integers (indexes) into dense vectors of fixed size.
44,Flatten,,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/flatten/,Flattens the input. Does not affect the batch size.
45,GRU,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/gru/,Gated Recurrent Unit - Cho et al. 2014.
46,GRUCell,#f1e2cc,Sequential,Recurrent Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell,"This class processes one step within the whole time sequence input, whereas tf.keras.layer.GRU processes the whole sequence."
47,GaussianDropout,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/gaussian_dropout/,"Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time."
48,GaussianNoise,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/gaussian_noise/,"Apply additive zero-centered Gaussian noise. This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs. As it is a regularization layer, it is only active at training time."
49,GlobalAveragePooling1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_average_pooling1d/,Global average pooling operation for temporal data.
50,GlobalAveragePooling2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_average_pooling2d/,Global average pooling operation for spatial data.
51,GlobalAveragePooling3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_average_pooling3d/,Global Average pooling operation for 3D data.
52,GlobalAvgPool1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_average_pooling1d/,Global average pooling operation for temporal data.
53,GlobalAvgPool2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_average_pooling2d/,Global average pooling operation for spatial data.
54,GlobalAvgPool3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_average_pooling3d/,Global Average pooling operation for 3D data.
55,GlobalMaxPool1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_max_pooling1d/,Global max pooling operation for temporal data.
56,GlobalMaxPool2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_max_pooling2d/,Global max pooling operation for spatial data.
57,GlobalMaxPool3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_max_pooling3d/,Global max pooling operation for 3D data.
58,GlobalMaxPooling1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_max_pooling1d/,Global max pooling operation for temporal data.
59,GlobalMaxPooling2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_max_pooling2d/,Global max pooling operation for spatial data.
60,GlobalMaxPooling3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/global_max_pooling3d/,Global max pooling operation for 3D data.
61,Hashing,,Preprocessing,Preprocessing Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing,A preprocessing layer which hashes and bins categorical features.
62,Input,,Input,Core Layers,,https://keras.io/api/layers/core_layers/input/,"Input() is used to instantiate a Keras tensor. A Keras tensor is a symbolic tensor-like object, which we augment with certain attributes that allow us to build a Keras model just by knowing the inputs and outputs of the model."
63,InputLayer,,Input,,,https://keras.io/api/layers/core_layers/input/,"Input() is used to instantiate a Keras tensor. A Keras tensor is a symbolic tensor-like object, which we augment with certain attributes that allow us to build a Keras model just by knowing the inputs and outputs of the model."
64,InputSpec,,Input,,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputSpec,"Specifies the rank, dtype and shape of every input to a layer."
65,IntegerLookup,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup/,"A preprocessing layer which maps integer features to contiguous ranges. This layer maps a set of arbitrary integer input tokens into indexed integer output via a table-based vocabulary lookup. The layer's output indices will be contiguously arranged up to the maximum vocab size, even if the input tokens are non-continguous or unbounded. The layer supports multiple options for encoding the output via output_mode, and has optional support for out-of-vocabulary (OOV) tokens and masking."
66,LSTM,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/lstm/,"Long Short-Term Memory layer - Hochreiter 1997. Recurrent neural networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language. Schematically, a RNN layer uses a for loop to iterate over the timesteps of a sequence, while maintaining an internal state that encodes information about the timesteps it has seen so far."
67,LSTMCell,#f1e2cc,Sequential,Recurrent Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell,"This class processes one step within the whole time sequence input, whereas tf.keras.layer.LSTM processes the whole sequence."
68,Lambda,,,Core Layers,,https://keras.io/api/layers/core_layers/lambda/,Wraps arbitrary expressions as a Layer object. The Lambda layer exists so that arbitrary expressions can be used as a Layer when constructing Sequential and Functional API models. Lambda layers are best suited for simple operations or quick experimentation.
69,Layer,,,,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer,This is the class from which all layers inherit.
70,LayerNormalization,#cbd5e8,Regularization,Normalization Layers,,https://keras.io/api/layers/normalization_layers/layer_normalization/,"Normalize the activations of the previous layer for each given example in a batch independently, rather than across a batch like Batch Normalization. i.e. applies a transformation that maintains the mean activation within each example close to 0 and the activation standard deviation close to 1."
71,LocallyConnected1D,#fdcdac,Convolution,Locally Connected Layers,,https://keras.io/api/layers/locally_connected_layers/locall_connected1d/,"Locally-connected layer for 1D inputs. The LocallyConnected1D layer works similarly to the Conv1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input."
72,LocallyConnected2D,#fdcdac,Convolution,Locally Connected Layers,,https://keras.io/api/layers/locally_connected_layers/locall_connected2d/,"Locally-connected layer for 2D inputs. The LocallyConnected1D layer works similarly to the Conv1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input."
73,Masking,,,Core Layers,,https://keras.io/api/layers/core_layers/masking/,"Masks a sequence by using a mask value to skip timesteps. For each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to mask_value, then the timestep will be masked (skipped) in all downstream layers (as long as they support masking)."
74,MaxPool1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/max_pooling1d/,"Max pooling operation for 1D temporal data. Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides. The resulting output, when using the ""valid"" padding option, has a shape of: output_shape = (input_shape - pool_size + 1) / strides)"
75,MaxPool2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/max_pooling2d/,Max pooling operation for 2D spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.
76,MaxPool3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/max_pooling2d/,"Max pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension."
77,MaxPooling1D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/max_pooling1d/,"Max pooling operation for 1D temporal data. Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides. The resulting output, when using the ""valid"" padding option, has a shape of: output_shape = (input_shape - pool_size + 1) / strides)"
78,MaxPooling2D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/max_pooling2d/,Max pooling operation for 2D spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.
79,MaxPooling3D,#e6f5c9,Pooling,Pooling Layers,,https://keras.io/api/layers/pooling_layers/max_pooling2d/,"Max pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension."
80,Maximum,,Tensor operation,Merging Layer,,https://keras.io/api/layers/merging_layers/maximum/,"Layer that computes the maximum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape)."
81,Minimum,,Tensor operation,Merging Layer,,https://keras.io/api/layers/merging_layers/minimum/,"Layer that computes the minimum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape)."
82,MultiHeadAttention,#f4cae4,Transformer,Attention Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention,"This is an implementation of multi-headed attention as described in the paper ""Attention is all you Need"" (Vaswani et al., 2017). If query, key, value are the same, then this is self-attention. Each timestep in query attends to the corresponding sequence in key, and returns a fixed-width vector."
83,Multiply,,Tensor operation,Merging Layer,,https://keras.io/api/layers/merging_layers/multiply/,"Layer that multiplies (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape)."
84,Normalization,,,Preprocessing Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization,"A preprocessing layer which normalizes continuous features. This layer will shift and scale inputs into a distribution centered around 0 with standard deviation 1. It accomplishes this by precomputing the mean and variance of the data, and calling (input - mean) / sqrt(var) at runtime."
85,Permute,,,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/permute/,Permutes the dimensions of the input according to a given pattern. Useful e.g. connecting RNNs and convnets.
86,RNN,#f1e2cc,Sequential,Recurrent Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN,Base class for recurrent layers.
87,RandomContrast,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_contrast/,A preprocessing layer which randomly adjusts contrast during training. This layer will randomly adjust the contrast of an image or images by a random factor. Contrast is adjusted independently for each channel of each image during training.
88,RandomCrop,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_crop/,"A preprocessing layer which randomly crops images during training. During training, this layer will randomly choose a location to crop images down to a target size. The layer will crop all the images in the same batch to the same cropping location."
89,RandomFlip,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_flip/,"Randomly flip each image horizontally and vertically. This layer will flip the images based on the mode attribute. During inference time, the output will be identical to input. Call the layer with training=True to flip the input."
90,RandomHeight,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_height/,"Randomly vary the height of a batch of images during training. Adjusts the height of a batch of images by a random factor. The input should be a 4-D tensor in the ""channels_last"" image data format."
91,RandomRotation,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_rotation/,"Randomly rotate each image. By default, random rotations are only applied during training. At inference time, the layer does nothing. If you need to apply random rotations at inference time, set training to True when calling the layer."
92,RandomTranslation,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_translation/,Randomly translate each image during training.
93,RandomWidth,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_width/,"Randomly vary the width of a batch of images during training. Adjusts the width of a batch of images by a random factor. The input should be a 4-D tensor in the ""channels_last"" image data format."
94,RandomZoom,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_zoom/,Randomly zoom each image during training.
95,RepeatVector,,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/repeat_vector/,Repeats the input n times.
96,Rescaling,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling/,A preprocessing layer which rescales input values to a new range. This layer rescales every value of an input (often an image) by multiplying by scale and adding offset.
97,Reshape,,Preprocessing,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/reshape/,Layer that reshapes inputs into the given shape.
98,Resizing,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/resizing/,"A preprocessing layer which resizes images. This layer resizes an image input to a target height and width. The input should be a 4D (batched) or 3D (unbatched) tensor in ""channels_last"" format. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats."
99,SeparableConv1D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/separable_convolution1d/,"Depthwise separable 1D convolution. This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels. If use_bias is True and a bias initializer is provided, it adds a bias vector to the output. It then optionally applies an activation function to produce the final output."
100,SeparableConv2D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/separable_convolution2d/,"Depthwise separable 2D convolution. Separable convolutions consist of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes the resulting output channels. The depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step. Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block."
101,SeparableConvolution1D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/separable_convolution1d/,"Depthwise separable 1D convolution. This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels. If use_bias is True and a bias initializer is provided, it adds a bias vector to the output. It then optionally applies an activation function to produce the final output."
102,SeparableConvolution2D,#fdcdac,Convolution,Convolution Layers,,https://keras.io/api/layers/convolution_layers/separable_convolution2d/,"Depthwise separable 2D convolution. Separable convolutions consist of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes the resulting output channels. The depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step. Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block."
103,SimpleRNN,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/simple_rnn/,Fully-connected RNN where the output is to be fed back to input.
104,SimpleRNNCell,#f1e2cc,Sequential,Recurrent Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNNCell,Cell class for SimpleRNN.
105,SpatialDropout1D,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/spatial_dropout1d/,"Spatial 1D version of Dropout. This version performs the same function as Dropout, however, it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead."
106,SpatialDropout2D,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/spatial_dropout2d/,"Spatial 2D version of Dropout. This version performs the same function as Dropout, however, it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead."
107,SpatialDropout3D,#cbd5e8,Regularization,Regularization Layers,,https://keras.io/api/layers/regularization_layers/spatial_dropout3d/,"Spatial 3D version of Dropout. This version performs the same function as Dropout, however, it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead."
108,StackedRNNCells,#f1e2cc,Sequential,Recurrent Layers,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/StackedRNNCells,Wrapper allowing a stack of RNN cells to behave as a single cell.
109,StringLookup,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup/,"A preprocessing layer which maps string features to integer indices. This layer translates a set of arbitrary strings into integer output via a table-based vocabulary lookup. This layer will perform no splitting or transformation of input strings. For a layer than can split and tokenize natural language, see the TextVectorization layer."
110,Subtract,,Tensor operation,Merging Layer,,https://keras.io/api/layers/merging_layers/subtract/,"Layer that subtracts two inputs. It takes as input a list of tensors of size 2, both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]), also of the same shape."
111,TextVectorization,,Preprocessing,Preprocessing Layers,,https://keras.io/api/layers/preprocessing_layers/core_preprocessing_layers/text_vectorization/,Text vectorization layer. This layer has basic options for managing text in a Keras model. It transforms a batch of strings (one sample = one string) into either a list of token indices (one sample = 1D tensor of integer token indices) or a dense representation (one sample = 1D tensor of float values representing data about the sample's tokens).
112,TimeDistributed,#f1e2cc,Sequential,Recurrent Layers,,https://keras.io/api/layers/recurrent_layers/time_distributed/,"This wrapper allows to apply a layer to every temporal slice of an input. Every input should be at least 3D, and the dimension of index one of the first input will be considered to be the temporal dimension."
113,UpSampling1D,,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/up_sampling1d/,Upsampling layer for 1D inputs. Repeats each temporal step size times along the time axis.
114,UpSampling2D,,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/up_sampling2d/,Upsampling layer for 2D inputs. Repeats the rows and columns of the data by size[0] and size[1] respectively.
115,UpSampling3D,,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/up_sampling3d/,"Upsampling layer for 3D inputs. Repeats the 1st, 2nd and 3rd dimensions of the data by size[0], size[1] and size[2] respectively."
116,Wrapper,,,,,https://www.tensorflow.org/api_docs/python/tf/keras/layers/Wrapper,"Wrappers take another layer and augment it in various ways. Do not use this class as a layer, it is only an abstract base class. Two usable wrappers are the TimeDistributed and Bidirectional wrappers."
117,ZeroPadding1D,#cccccc,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/zero_padding1d/,Zero-padding layer for 1D input (e.g. temporal sequence).
118,ZeroPadding2D,#cccccc,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/zero_padding2d/,"Zero-padding layer for 2D input (e.g. picture). This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor."
119,ZeroPadding3D,#cccccc,Tensor operation,Reshaping Layer,,https://keras.io/api/layers/reshaping_layers/zero_padding3d/,Zero-padding layer for 3D data (spatial or spatio-temporal).
